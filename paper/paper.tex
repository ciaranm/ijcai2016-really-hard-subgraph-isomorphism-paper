% vim: set spell spelllang=en tw=100 :

\documentclass[letterpaper]{article}
\usepackage[pass]{geometry}

\usepackage{ijcai13}
\usepackage{times}
\usepackage{complexity}
\usepackage{microtype}
\usepackage{gnuplot-lua-tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{placeins}
\usepackage{cleveref}

% \usepackage{showframe}
\usepackage{lipsum}

\title{Really Hard Instances for the Subgraph Isomorphism Problem}
\author{Ciaran McCreesh\thanks{This work was supported by the Engineering and Physical Sciences
    Research Council [grant number EP/K503058/1]} \and Patrick Prossser \and James Trimble \\
University of Glasgow, Glasgow, Scotland \\
c.mccreesh.1@research.gla.ac.uk}

\begin{document}

\maketitle

\begin{abstract}
    How to generate hard random instances for variants of the subgraph isomorphism problem. Phase
    transition between satisfiable and unsatisfiable instances, with corresponding complexity peak
    seen in three different solvers. For the induced variant, behaviour is much more complicated,
    with an unexpectedly hard region. This remains hard under pseudo-boolean and mixed integer
    encodings, and reduction to clique.
\end{abstract}

\section{Introduction}

The \emph{non-induced subgraph isomorphism problem} is to find an injective mapping from a given
pattern graph to a given target graph which preserves adjacency---in essence, we are ``finding a
copy of'' the pattern inside the target. The \emph{induced} variant of the problem additionally
requires that the mapping preserve non-adjacency, so there are no ``extra edges'' in the copy of the
pattern that we find. Despite these problems being \NP-complete, modern practical subgraph
isomorphism algorithms can handle problem instances with many hundreds of vertices in the pattern
graph, and up to ten thousand vertices in the target graph
\cite{Cordella:2004,Solnon:2010,Audemard:2014,McCreesh:2015}.

However, these algorithms cannot handle \emph{arbitrary} instances of this size. The experimental
evaluations in these papers were performed using a mix of real-world instances (from applications
??), and randomly generated graph pairs. Using random instances can be beneficial, because it
provides a way of generating arbitrarily many instances cheaply, and reduces the risk of
over-fitting when tuning design parameters. The instances used were generated by taking a subgraph
of a random graph (using various models, including scale-free and bounded degree) and permuting the
vertices.  This is not ideal: such instances are guaranteed to be satisfiable, and so existing
benchmark suites contain relatively few non-trivial unsatisfiable instances. This introduces a new
source of bias when designing algorithms.

However, generating non-trivial unsatisfiable random instances is not straightforward. Using a
pattern graph from one of the random suites with the ``wrong'' target graph tends to give either a
trivially unsatisfiable instance, or a satisfiable instance. In particular, it is \emph{not} the
case that a relatively small random graph is very unlikely to appear in a larger random graph.

Here we present and evaluate a new method for creating random pattern/target pairs which can
generate both satisfiable and unsatisfiable instances. Our work builds upon the widely studied phase
transition phenomena observed in satisfiability and graph colouring problems ?? cite stuff. However,
we have three control parameters rather than one: we can independently alter the density of the
pattern graph, the density of the target graph, and the relative orders (number of vertices) of the
pattern and target graphs.  For non-induced isomorphisms, with the correct choice of parameters
there is a phase transition from satisfiable to unsatisfiable, and as expected we see a complexity
peak occur (with three different solvers) near this phase transition.

For certain choices of parameter for induced isomorphisms, there are two phase transitions, going
from satisfiable to unsatisfiable, and then from unsatisfiable back to satisfiable. Again, when
going from satisfiable to unsatisfiable (from either direction), instances go from being trivial to
really hard to solve. However, each of the three solvers we tested also finds the central
unsatisfiable region to be really hard---this is surprising, since this region is apparently
over-constrained. ?? Except really it's because solvers can't handle edges and non-edges
simultaneously. To show that this is not a simple weakness of subgraph isomorphism algorithms, we
verify that this region is also hard when using use a pseudo-boolean solver, a mixed integer solver,
and clique encoding.

\subsection{Definitions}

?? Some stuff about order, density, random, $\rightarrowtail$ and $\hookrightarrow$.

\lipsum[2]

\subsection{Experimental Setup}

Our experiments were performed on systems with Intel Xeon E5-4650 v2 (Q1'14) CPUs and 768GBytes RAM
(although this much RAM was not needed), running Scientific Linux release 6.7.   ?? Software
versions. Clasp 3.1.3, Gurobi 6.0.5, Glasgow, LAD version 2, VFLib. Software was compiled using GCC
4.9.

?? Stuff about runtimes and recursive calls. We are not aiming to compare solvers; rather, we are
looking for solver-independent behaviour.

\section{Non-Induced Subgraph Isomorphisms}

\begin{figure}[t]
    \input{gen-graph-phase-transition.tex}
    \caption{With a fixed a pattern size of 20, a target size of 150, a target density of 0.4, and
    varying pattern density, we observe a phase transition and complexity peak in the non-induced
    variant. Each point represents one instance. The lines show mean search effort, and mean
    proportion satisfiable, using a larger sample size.}
    \label{figure:phase-transition}
\end{figure}

Suppose we arbitrarily decide upon a pattern size of 20, a target size of 150, and a fixed target
density of 0.40. As we vary the pattern density from 0 to 1, we would expect to see a shift from
entirely satisfiable instances (with no edges in the pattern, we can always find a match) to
entirely unsatisfiable instances (a maximum clique in this size and density of target graph will
usually have between 9 and 12 vertices). Indeed, \cref{figure:phase-transition} shows that this is
the case: the line (and the points show a subset of the samples) ?? describe this a bit more, find
the 0.5 SAT mark.

Some stuff about the complexity peak in the Glasgow solver. This looks remarkably similar to 3SAT.

\begin{figure}[t]
    \input{gen-graph-non-induced.tex}
    \caption{Behaviour of algorithms on the non-induced variant. Each point is the average of ten
        runs. For each plot, the x-axis is the pattern density and the y-axis is the target
        density, both from 0 to 1. Along the top row, we show the proportion of instances which are
        satisfiable; the white bands shows the phase transitions. On the second row, we show the
        number of search nodes used by the Glasgow algorithm, on the third row, the number of
        search nodes used by the LAD algorithm, and the fourth, VF2; the dark regions indicate
        ``really hard'' instances.}
    \label{figure:non-induced}
\end{figure}

In the top row of \cref{figure:non-induced} we show the phase transition for the non-induced
variant, for patterns of order 10, 20 and 30, a target of order 150, and varying pattern (x-axis)
and target (y-axis) densities. Inside the orange region, at the bottom right of each plot, every
instance is unsatisfiable---here we are trying to find a dense pattern in a sparse target. In the
purple region, at the top left, every instance is satisfiable---we are looking for a sparse pattern
in a dense target (which is easy, since we only have to preserve adjacency, not non-adjacency). The
white band between the regions shows the location of the phase transition: here, roughly half the
instances are satisfiable.

On subsequent rows, we show the average difficulty of different algorithms.  We measure search
nodes. Cannot be used to compare performance of algorithms directly, but this does show that each
solver found the same set of instances difficult.

Satisfiable is easy, until very close to the phase transition. Unsatisfiable is much harder than
satisfiable. This is solver-independent, although VF2 is terrible.

?? Are unsatisfiable instances on the phase transition much harder than satisfiable ones?

\lipsum[4]

\subsection{Locating the Phase Transition}

?? Can we predict where that line is?

\lipsum[5]

\lipsum[6]

\section{Induced Isomorphisms}

In \cref{figure:induced} we show the induced behaviour (modified Glasgow to include the complement
as a supplemental graph).

Pattern size 10, what we expect. Patterns 20 and 30 have large unsatisfiable regions in the middle,
but these remain hard. Pattern sizes 14, 15 and 16 show the transition between the two styles.

Odd unsat with LAD at the top right (not EHPs), trivial for Glasgow: mapping a non-clique into a
clique. Glasgow looks at non-edges and can see immediately that no mapping is possible.

Note that this is solver-independent.

\lipsum[7]

\lipsum[8]

\begin{figure*}[t]
    \input{gen-graph-induced.tex}
    \caption{Behaviour of algorithms on the induced variant, shown in the style
    of \cref{figure:non-induced}. The second row shows a bound on the satisfiable region, by
    considering where a \emph{non-}induced isomorphism may also be a non-induced isomorphism between
    complement graphs.}\label{figure:induced}
\end{figure*}

\subsection{Predicting Induced Behaviour}

?? Graph showing the product of satisfiable with vertical flip, min (unsat) and max (sat) of search
nodes with vertical flip.

This suggests that we're not able to make use of adjacency and non-adjacency simultaneously.

\lipsum[9]

\lipsum[10]

\section{Other Encodings and Solvers}

\begin{figure*}[t]
    \input{gen-graph-sat.tex}
    \caption{Behaviour of other solvers on the induced variant on smaller graphs, shown in the style of
        \cref{figure:non-induced}. The second row shows the number of search nodes used by the Glasgow
        algorithm, the third row shows the number of decisions made by the Clasp pseudo-boolean solver,
        the fourth row shows the number of search nodes used by a clique encoding, and the fifth a mixed
        integer encoding with Gurobi.}\label{figure:alt}
\end{figure*}

Is this just a weakness of current subgraph isomorphism solvers? In \cref{figure:alt} we repeat the
experiments on smaller pattern and target graphs, using different solving techniques. Although these
techniques are not competitive in absolute terms, we wish to see if the same pattern of behaviour
occurs.

Direct pseudo-boolean encoding: variables for each assignment, cardinality constraints, edge and
non-edge constraints. We use the Clasp solver. We see that hard instances remain hard, including
inside the central region, and that the easy satisfiable instances remain easy. (Although not
presented here, we also tried an equivalent SAT encoding with the Glucose solver, and saw very
similar performance.)

Clique encoding: association graph, a version of BBMC modified to solve the decision problem. The
hard instances in the central region remain hard. Additionally, some of the easy satisfiable
instances become hard. Possible weakness of clique algorithms for this kind of input.

MIP encoding with Gurobi.

?? \cite{Anton:2009}

?? \cite{Lipets:2009}

\section{Conclusion}

\lipsum[11]

\lipsum[12]

\bibliographystyle{named}
\bibliography{paper}

\end{document}
